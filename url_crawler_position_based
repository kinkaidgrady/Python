#this is a basic url crawler to follow a predetermined number of links based on an input position to start at and continue through x number of times

import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup
import ssl

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = input("Enter url: ")

count = int(input('Enter count: '))
pos = int(input('Enter position: '))-1

urllist=list()

for i in range(count):
    html = urllib.request.urlopen(url)
    soup = BeautifulSoup(html, 'html.parser')
    tags = soup('a')
    print('Retrieving:', url)
    taglist = list()
    for tag in tags:
        y = tag.get('href', None)
        taglist.append(y)

    url = taglist[pos]

    urllist.append(url)

print("Last Url:",urllist[-1])
